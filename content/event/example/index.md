---
title: 'Un viaje a través de los modelos de visión y lenguaje: avances, aplicaciones y desafíos'

event: EVIC 2023
event_url: https://www.evic.cl/

location: Facultad de Ciencias Físicas y Matemáticas, Universidad de Chile, Santiago, Chile.
# address:
#   street: 450 Serra Mall
#   city: Stanford
#   region: CA
#   postcode: '94305'
#   country: United States

summary: 'A journey through vision and language models: advances, applications and challenges.'
abstract: 'Artificial intelligence (AI) is revolutionizing the way we live. However, there is still a long way to go before we can consider AI as an intelligence similar to our own. Humans explore the world through our five senses, our perception and learning mode is inherently multi-modal. How can we move towards AI models that learn in a more “human-like” way?
Vision-language models (VLMs) represent a big step in this direction. These are models at the intersection of computer vision and natural language processing, capable of modeling images, text and their relationships. Current VLMs allow our computers to understand, generate descriptions or answer questions about images in a manner similar to humans.
In this tutorial we will take a walk through the history and development of current vision and language models, explore existing architectures, training practices and their various applications.'

# Talk start and end times.
#   End time can optionally be hidden by prefixing the line with `#`.
date: '2023-12-14'
# date_end: '2030-06-01T15:00:00Z'
# all_day: false

# Schedule page publish date (NOT talk date).
# publishDate: '2017-01-01T00:00:00Z'

authors:
  - admin

tags:
- Vision and language

# Is this a featured talk? (true/false)
featured: false

# image:
#   caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/bzdhc5b3Bxs)'
#   focal_point: Right

#links:
#  - icon: twitter
#    icon_pack: fab
#    name: Follow
#    url: https://twitter.com/georgecushen
# url_code: 'https://github.com'
# url_pdf: ''
url_slides: 'https://drive.google.com/file/d/139STlEpDw5S9jBMopgeNjK5Y--g_1cX8/view?usp=drive_link'
# url_video: 'https://youtube.com'

# Markdown Slides (optional).
#   Associate this talk with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides = "example-slides"` references `content/slides/example-slides.md`.
#   Otherwise, set `slides = ""`.
# slides: ""

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
# projects:
#   - example


# {{% callout note %}}
# Click on the **Slides** button above to view the built-in slides feature.
# {{% /callout %}}

# Slides can be added in a few ways:

# - **Create** slides using Hugo Blox Builder's [_Slides_](https://docs.hugoblox.com/reference/content-types/) feature and link using `slides` parameter in the front matter of the talk file
# - **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file
# - **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://docs.hugoblox.com/reference/markdown/).

# Further event details, including [page elements](https://docs.hugoblox.com/reference/markdown/) such as image galleries, can be added to the body of this page.

---